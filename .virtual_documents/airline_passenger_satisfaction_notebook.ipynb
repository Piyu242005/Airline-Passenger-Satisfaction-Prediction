


# 1) Setup & Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import warnings
warnings.filterwarnings('ignore')
sns.set(style='whitegrid')

print('Libraries imported successfully')



# 2) Load Data
# Make sure 'train.csv' is in the same folder as this notebook.

if not any(os.path.exists(fname) for fname in ['train.csv', 'test.csv']):
    print('WARNING: train.csv and test.csv not found in working directory.\nPlease download the Airline Passenger Satisfaction dataset from Kaggle and place train.csv here.')

# Try loading train.csv
try:
    data = pd.read_csv('train.csv')
    print('Loaded train.csv — shape:', data.shape)
except Exception as e:
    print('Could not load train.csv:', e)
    data = pd.DataFrame()

# Show top rows if loaded
if not data.empty:
    display(data.head())
    display(data.info())






# Quick EDA (run only if data loaded)
if data.empty:
    raise SystemExit('Load the dataset first (train.csv) and re-run this cell.')

# Target distribution
plt.figure(figsize=(6,4))
ax = sns.countplot(x='satisfaction', data=data)
ax.set_title('Satisfaction Distribution')
plt.show()


# Missing values
print('\nMissing values per column:')
print(data.isnull().sum())


# Numeric summary
display(data.describe())


# Correlation heatmap for numeric columns
numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
plt.figure(figsize=(12,8))
sns.heatmap(data[numeric_cols].corr(), annot=False, cmap='coolwarm')
plt.title('Correlation heatmap (numeric features)')
plt.show()





# Visualization: Distribution of Travel Class by Age

# Load data using the existing 'data' variable if available, otherwise load from CSV
if 'data' in locals() and not data.empty:
    df = data.copy()
else:
    df = pd.read_csv('train.csv')

# --- Preprocessing for plotting ---
# Restrict age range to sensible values (adjust if needed)
min_age, max_age = 18, 70
age_range = list(range(min_age, max_age + 1))

# Ensure Age is integer and filter
df['Age'] = pd.to_numeric(df['Age'], errors='coerce')
df = df.dropna(subset=['Age'])
df['Age'] = df['Age'].astype(int)
df = df[(df['Age'] >= min_age) & (df['Age'] <= max_age)]

# Use 'Class' column for different categories (Eco, Eco Plus, Business)
if 'Class' in df.columns:
    category_col = 'Class'
    travel_classes = df[category_col].dropna().unique().tolist()
elif 'Type of Travel' in df.columns:
    category_col = 'Type of Travel'
    travel_classes = df[category_col].dropna().unique().tolist()
else:
    print("Error: Expected columns not found in dataset")
    travel_classes = []

if travel_classes:
    # --- Figure layout ---
    n = len(travel_classes)
    cols = min(3, n)
    rows = int(np.ceil(n / cols))
    
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 4), constrained_layout=True)
    
    # Handle single subplot case
    if n == 1:
        axes = [axes]
    else:
        axes = axes.flatten() if n > 1 else [axes]
    
    # Plotting
    for i, category in enumerate(travel_classes):
        ax = axes[i]
        sub = df[df[category_col] == category]
        
        # Count per age (every integer age between min_age and max_age)
        counts = sub['Age'].value_counts().reindex(age_range, fill_value=0).sort_index()
        ages = np.array(counts.index)
        vals = counts.values
        
        # Bar chart
        ax.bar(ages, vals, width=0.8, alpha=0.7, color='skyblue', edgecolor='black')
        
        # Smooth trend (rolling mean)
        smooth = pd.Series(vals, index=ages).rolling(window=5, center=True, min_periods=1).mean()
        ax.plot(ages, smooth, color='red', linewidth=2, label='Trend')
        
        # Labels and styling
        ax.set_title(f'{category}', fontsize=12, fontweight='bold')
        ax.set_xlabel('Age', fontsize=10)
        ax.set_ylabel('Number of Passengers', fontsize=10)
        ax.set_xlim(min_age - 1, max_age + 1)
        ax.set_xticks(list(range(min_age, max_age + 1, 5)))
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
    
    # Clear any unused subplots
    for j in range(n, len(axes)):
        fig.delaxes(axes[j])
    
    fig.suptitle(f'Distribution of {category_col} by Age', fontsize=16, fontweight='bold')
    plt.show()
else:
    print("No data to plot")



plt.figure(figsize=(10, 5))

# Histogram with KDE
sns.histplot(
    data['Age'], 
    bins=20, 
    kde=True, 
    color='salmon', 
    edgecolor='black',
    alpha=0.4
)

plt.title('Customer Age Distribution')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()



# Age groups on x-axis
age_groups = ['0-20', '21-30', '31-40', '41-50',
              '51-60', '61-70', '71-80', '81-90', '91-100']

# Number of tickets for each age group (example values – change as needed)
tickets = [320, 1600, 1550, 1600, 1670, 1580, 150, 0, 0]

plt.figure(figsize=(8, 4))
plt.bar(age_groups, tickets, color='skyblue', edgecolor='black')

plt.title('Tickets Raised by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Number of Tickets Raised')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()






# Preprocessing
# 1) Drop rows with NA in target if any
if data['satisfaction'].isnull().any():
    data = data.dropna(subset=['satisfaction'])


# 2) Simple fill for other missing values (if any)
for col in data.columns:
    if data[col].isnull().sum() > 0:
        if data[col].dtype == 'O':
            data[col].fillna(data[col].mode()[0], inplace=True)
        else:
            data[col].fillna(data[col].median(), inplace=True)


# 3) Encode categorical variables
cat_cols = data.select_dtypes(include=['object']).columns.tolist()
print('Categorical columns:', cat_cols)
le_dict = {}
for col in cat_cols:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col].astype(str))
    le_dict[col] = le


# 4) Prepare features and target
X = data.drop(['satisfaction'], axis=1)
y = data['satisfaction']

print('\nFeature matrix shape:', X.shape)
print('Target shape:', y.shape)


# 5) Optional: Scale numeric features
num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# Save encoders and scaler for later (in memory) - will save model & pipeline later
import pickle
with open('label_encoders.pkl', 'wb') as f:
    pickle.dump(le_dict, f)
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print('Preprocessing complete. Encoders and scaler saved locally.')








# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)
print('Train set:', X_train.shape, 'Test set:', X_test.shape)

# Train Random Forest
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# Predict
y_pred = rf.predict(X_test)

# Evaluate
print('Accuracy:', accuracy_score(y_test, y_pred))
print('\nClassification Report:\n', classification_report(y_test, y_pred))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()









# Feature importance
feat_imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
print(feat_imp.head(15))


plt.figure(figsize=(8,6))
feat_imp.head(15).plot(kind='barh')
plt.gca().invert_yaxis()
plt.title('Top 15 Feature Importances')
plt.show()





# Small GridSearch (optional — may take time depending on machine)
# Uncomment to run
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5]
}
grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, scoring='accuracy')
grid.fit(X_train, y_train)
print('Best params:', grid.best_params_)
best_rf = grid.best_estimator_









# Save model and artifacts
joblib.dump(rf, 'rf_airline_satisfaction_model.pkl')
print('Saved Random Forest model to rf_airline_satisfaction_model.pkl')

# Artifacts saved: label_encoders.pkl, scaler.pkl, rf_airline_satisfaction_model.pkl
print('Saved artifacts: label_encoders.pkl, scaler.pkl, rf_airline_satisfaction_model.pkl')




